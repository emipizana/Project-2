---
title: "Titanic Data Analysis"
author: "Emiliano Piza√±a"
date: "5/11/2022"
output:
  html_document: default
  pdf_document: default
---
```{r Load Libraries, include=FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(stringr)
library(tidyverse)
library(dtplyr)
library(tidyr)
library(MASS)
library(randomForest)
library(purrr)
library(caret)
```
## Titanic Prediction

**Introduction**

*Titanic was a British passenger liner, which sank in the North Atlantic Ocean on 15 April 1912 after striking an iceberg. In this project we have data from the passengers and we trying to predict if they survived.*


```{r}
#Reading Data
train_df <- read.csv("train_titanic.csv")
test_df <- read.csv("test_titanic.csv")
```

**Basic Data Summary**
```{r}
summary(train_df)  #Summary
str(train_df)  #Structure
head(train_df)  

ggplot(train_df, aes(x=factor(Survived)))+
  geom_bar(stat="count", width=0.7, fill="steelblue")+
  theme_minimal() +  labs(title = "Survived",
                          x = "Survivors", y = "Frequency (Count)")

```
**Data info test data**
```{r}
summary(test_df)
str(test_df)
head(test_df)
```

**Cleaning Data**

*First we take a look at the data in general and see if there are NA values*
```{r}
missing_values <- train_df  %>%
  summarise_all(list(~is.na(.))) %>%
  pivot_longer(everything(),
               names_to = "variables", values_to="missing_data") %>%
  count(variables, missing_data) 

ggplot(missing_values, aes(y = variables, x = n, fill = missing_data)) + 
  geom_col()
```
*We can see that all the NA values are in the variable Age.*

**NA Values in the age variable train data**
```{r}
null_cols <- which(colSums(is.na(train_df))>0)

no_missingval <- sum(is.na(train_df$Age))

train_df$Age <- replace_na(train_df$Age, mean(train_df$Age, na.rm = TRUE))
train_df$Age <- round(train_df$Age)
```
**Test data**
```{r}
missing_values_test <- test_df  %>%
  summarise_all(list(~is.na(.))) %>%
  pivot_longer(everything(),
               names_to = "variables", values_to="missing_data") %>%
  count(variables, missing_data) 

ggplot(missing_values_test, aes(y = variables, x = n, fill = missing_data)) + 
  geom_col()

null_cols_test <- which(colSums(is.na(test_df))>0)

no_missingval_test <- sum(is.na(test_df$Age))

test_df$Age <- replace_na(test_df$Age, mean(test_df$Age, na.rm = TRUE))
test_df$Age <- round(test_df$Age)


for(i in 1:length(test_df$Cabin)){
  if(test_df$Cabin[i] == ""){
    test_df$Cabin[i] <- "No cabin recorded"
  }
}


sprintf("We have left %1.0f missing values" ,sum(is.na(test_df)))
sum(is.na(test_df$Fare))

test_df$Fare <- replace_na(test_df$Fare, mean(test_df$Fare, na.rm = TRUE))
sprintf("We have left %1.0f missing values" ,sum(is.na(test_df)))

```

*In this case we replaced the NA values with the mean of the other age values. There are many other ways to deal with the NA values that can be more efficient.*

**Missing values in Cabin**

*Note that there are also missing values in the Cabin variable but they are not NA values.*
```{r}
for(i in 1:length(train_df$Cabin)){
  if(train_df$Cabin[i] == ""){
    train_df$Cabin[i] <- "No cabin recorded"
  }
}
```
*Now we can make sure there are no more NA values in our data.*
```{r}
sprintf("We have left %1.0f missing values" ,sum(is.na(train_df)))
```
**Checking test data**
```{r}
missing_values_test <- test_df  %>%
  summarise_all(list(~is.na(.))) %>%
  pivot_longer(everything(),
               names_to = "variables", values_to="missing_data") %>%
  count(variables, missing_data) 

ggplot(missing_values_test, aes(y = variables, x = n, fill = missing_data)) + 
  geom_col()
```


**Name Variable train data**

*One of the categorical variables is the name of the passenger. In this case we will only use the title name of the name variable.*
```{r}
train_df <- train_df %>%
  mutate(Title_1 = str_split(train_df$Name, ","))

vec <- c()
for (i in 1:length(train_df$Title_1)){
  vec <- rbind(vec, train_df$Title_1[[i]][2])
}

vec_1 <- c()
for (i in 1:length(vec)){
  vec_1 <- rbind(vec_1, word(vec[i], start = 1, end = 2, sep = fixed(" ")))
}

train_df <- train_df %>%
  mutate(Title_name = vec_1)
  

Title_freq_graph <- ggplot(train_df, aes(x = Title_name)) + geom_bar()
Title_freq_graph

Title_freq <- train_df %>% 
  count(Title_name)
Title_freq

```
*Note that there are a lot of Title names so we will only stay with the 5 more used and we will group the rest of them as "Other".*
```{r}
for(i in 1:length(train_df$Title_name)){
  if(train_df$Title_name[i] %in% c(" Mr.", " Mrs.", " Miss.", " Mrs.", " Master."))
    train_df$Title_name[i] <- str_replace_all(train_df$Title_name[i]," ","")
  else
    train_df$Title_name[i] <- "Other"
}
```

*Now we can see the distribution of the name titles*
```{r}
Title_freq_graph <- ggplot(train_df, aes(x = Title_name)) + geom_bar()
Title_freq_graph

Title_freq <- train_df %>% 
  count(Title_name)
Title_freq
```
**Name Variable train data**
```{r}
test_df <- test_df %>%
  mutate(Splitname = str_split(test_df$Name, ","))

vectest <- c()
for (i in 1:length(test_df$Splitname)){
  vectest <- rbind(vectest, test_df$Splitname[[i]][2])
}

vectest_1 <- c()
for (i in 1:length(vectest)){
  vectest_1 <- rbind(vectest_1, word(vectest[i], start = 1, end = 2, sep = fixed(" ")))
}

test_df <- test_df %>%
  mutate(Title_name = vectest_1)


Title_freq_graph_test <- ggplot(test_df, aes(x = Title_name)) + geom_bar()
Title_freq_graph_test

Title_freq_test <- test_df %>% 
  count(Title_name)
Title_freq_test
```
```{r}
for(i in 1:length(test_df$Title_name)){
  if(test_df$Title_name[i] %in% c(" Mr.", " Mrs.", " Miss.", " Mrs.", " Master."))
    test_df$Title_name[i] <- str_replace_all(test_df$Title_name[i]," ","")
  else
    test_df$Title_name[i] <- "Other"
}

Title_freq_graph_test <- ggplot(test_df, aes(x = Title_name)) + geom_bar()
Title_freq_graph

Title_freq_test <- test_df %>% 
  count(Title_name)
Title_freq_test
```
**Ticket variable train data**

*In this case we are assuming that the tickets that have just numbers are "Regular Tickets"*
```{r}
for(i in 1:length(train_df$Ticket)){
  if(grepl(" ", train_df$Ticket[i])){
    train_df$Ticket[i] <- word(train_df$Ticket[i], start = 1, end = 1, sep = fixed(" "))
  }
  else
    train_df$Ticket[i] <- "Regular Ticket"
}

Ticket_freq_graph <- ggplot(train_df, aes(x = Ticket)) + geom_bar()
Ticket_freq_graph
train_df %>% 
  count(Ticket) %>%
  arrange(desc(n))
```
*We can see that most of the tickets are just normal, we cant treat this variable as a numeric variable but we don't think that will make much sense*

**Ticket variable test data**
```{r}
for(i in 1:length(test_df$Ticket)){
  if(grepl(" ", test_df$Ticket[i])){
    test_df$Ticket[i] <- word(test_df$Ticket[i], start = 1, end = 1, sep = fixed(" "))
  }
  else
    test_df$Ticket[i] <- "Normal Ticket"
}
Ticket_freq_graph_test <- ggplot(test_df, aes(x = Ticket)) + geom_bar()
Ticket_freq_graph_test
test_df %>% 
  count(Ticket) %>%
  arrange(desc(n))
```
**Embarked train variable**
```{r}
train_df <- train_df %>% 
  mutate(Embarked = replace(Embarked, Embarked == "", NA)) %>% 
  na.omit()
```
**Variables Dummification train data**
```{r}
cat_variables <- c("Survived", "Pclass", "Sex", "SibSp",
                   "Title_name")

train_df[cat_variables] <- lapply(train_df[cat_variables], factor)
train_df[cat_variables] %>% head()

str(train_df[cat_variables])
```
**Variables Dummification test data**
```{r}
cat_variables_test <- c("Pclass", "Sex", "SibSp",
                   "Title_name")

test_df[cat_variables_test] <- lapply(test_df[cat_variables_test], factor)
test_df[cat_variables_test] %>% head()

str(test_df[cat_variables_test])
```

**Fare Variable (numerical variable)**

*First we box plot to get an idea of the variable distribution and the outlier values.*
```{r}
fare_graph <- ggplot(train_df, aes(x = Fare)) + geom_boxplot(outlier.colour="red", outlier.shape=16,
                                              outlier.size=2)
fare_graph
```
*In this case we are only removing the passenger with a fare larger than 500*
```{r}
train_df <- train_df %>%
  filter(Fare < 400)

ggplot(train_df, aes(x = Fare)) + geom_boxplot(outlier.colour="red", outlier.shape=16,
                                               outlier.size=2)

train_df$Fare <- scale(train_df$Fare, center = TRUE, scale=TRUE)

head(train_df$Fare)
```
**Fare variable test data**
```{r}
test_df$Fare <- scale(test_df$Fare, center = TRUE, scale=TRUE)
```
**Age and parch variable (numerical) train data**
```{r}
age_graph <- ggplot(train_df, aes(Age)) + geom_boxplot(outlier.colour="red", outlier.shape=16,
                                                       outlier.size=2)
age_graph
sprintf("The minimum value is %1.0f ", min(train_df$Age))
```
*For the age variable we are only making sure that all ages are positive or zero*

```{r}
train_df <- train_df %>% 
  filter(Age >= 0)
train_df$Age <- scale(train_df$Age, center = TRUE, scale = TRUE)
train_df$Parch <- scale(train_df$Parch, center = TRUE, scale = TRUE)
```
**Age and Parch variable scaling test data **
```{r}
test_df$Age <- scale(test_df$Age, center = TRUE, scale = TRUE)
train_df$Parch <- scale(train_df$Parch, center = TRUE, scale = TRUE)
```

```{r}

```

**Logistical Regresion **

*Our first model is the logistical regression, taking 8 explanatory variables as we can see in fmla.*
```{r}
fmla <- as.formula(Survived ~ Pclass + Sex + SibSp + Parch + Embarked + Title_name
                   + Age + Fare)
log_model <- glm(fmla, train_df, family = "binomial")
summary(log_model)

log_model_prob <- predict(log_model, train_df, type = "response")
head(log_model_prob)
log_model_pred <- as.factor(round(log_model_prob))
head(log_model_pred)
```
**Table**
```{r}
log_model_table <- caret::confusionMatrix(log_model_pred, train_df$Survived)
log_model_table
```
*As we can see, the logistical model has an accuracy of 83%.*

**Random Forest**
```{r}
randomforest_model <- randomForest(fmla, train_df, ntree = 500)
randomforest_pred <- predict(randomforest_model,train_df)
head(randomforest_pred)
```

```{r}
randomforest_table <- caret::confusionMatrix(randomforest_pred, train_df$Survived)
randomforest_table
```
```{r}
plot(randomforest_model)
```
*On the other hand the Random Forest model has an accuracy of 90%. So we are stayin with the random forest model.*

**Tasting Data Prediction**
```{r}
test_prediction <- predict(randomforest_model, test_df)

final_prediction <- test_df %>% 
  dplyr::select(PassengerId) %>% 
  mutate(Survived = test_prediction)

head(final_prediction)
```
